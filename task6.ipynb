{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (4.42.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (0.23.5)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhay\\anaconda3\\envs\\pdf-que-ans\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -q -q PyMuPDF\n",
    "%pip install transformers -U\n",
    "\n",
    "import fitz \n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(document.page_count):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from pdf\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings from ResoluteAI.in!\n",
      "Mandatory Tasks : Task 1, 2, 3 should be mandatorily completed.\n",
      "Option\n"
     ]
    }
   ],
   "source": [
    "pdf_path = 'RAI SW - AI Labs - AI Engineer July 24.pdf'\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "\n",
    "sentences = re.split(r'[.!?;]', text)\n",
    "\n",
    "sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "print(len(sentences))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 384])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model_encoder = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "def embed(query):\n",
    "    encoded_input = tokenizer(query, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model_encoder(**encoded_input)\n",
    "\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    return sentence_embeddings\n",
    "\n",
    "embeddings = embed(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "query = \"How to increase chance of selection?\"\n",
    "\n",
    "query_embedding = embed([query])\n",
    "print(query_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Also share your algorithms train accuracy and mention the reason behind choosing your algorithm',\n",
       " ' Approach for all tasks and reading of instructions will be given higher preference over accuracy and code',\n",
       " ' Datewise number of picking and placing activity done',\n",
       " ' However if stuck at any one task please move to next and complete as much as possible before the deadline',\n",
       " ' Need to complete all first three tasks mentioned',\n",
       " ' Good Luck ',\n",
       " ' Please use Operations Management',\n",
       " ' 5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_sentences(query, embeddings, sentences):\n",
    "    query_embedding = embed([query])\n",
    "    similarities = F.cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    cutoff_score = 0.2\n",
    "    top_idx = similarities.argsort(descending=True)[:8]\n",
    "    return [sentences[i] for i in top_idx]\n",
    "\n",
    "top_sentences(query, embeddings, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install google-generativeai\n",
    "\n",
    "gemini_api_key = '#########'\n",
    "\n",
    "\"\"\"\n",
    "Install the Google AI Python SDK\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\n",
    "See the getting started guide for more information:\n",
    "https://ai.google.dev/gemini-api/docs/get-started/python\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "\n",
    "# Create the model\n",
    "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model_genai = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"You will be provided with context from a PDF document. Analyze the context and respond to queries based on the information given.\",\n",
    ")\n",
    "\n",
    "chat_session = model_genai.start_chat(\n",
    "  history=[]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=glm.GenerateContentResponse({'candidates': [{'content': {'parts': [{'text': \"The user needs to complete **5 tasks** in total. \\n\\nHere's the breakdown:\\n\\n* **Mandatory:** Tasks 1, 2, and 3 (3 tasks)\\n* **Optional:** Any 2 tasks from tasks 4 to 11 (2 tasks) \\n\"}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'token_count': 0, 'grounding_attributions': []}]}),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "query = 'How many tasks does user needs to do?'\n",
    "context = top_sentences(query, embeddings, sentences)\n",
    "\n",
    "message = {\n",
    "    \"role\" : \"user\",\n",
    "    \"parts\" : [\n",
    "        f\"Context: {context}\",\n",
    "        f\"query : {query}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = chat_session.send_message(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>The user needs to complete <strong>5 tasks</strong> in total. </p>\n",
      "<p>Here's the breakdown:</p>\n",
      "<ul>\n",
      "<li><strong>Mandatory:</strong> Tasks 1, 2, and 3 (3 tasks)</li>\n",
      "<li><strong>Optional:</strong> Any 2 tasks from tasks 4 to 11 (2 tasks) </li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "# %pip install markdown\n",
    "\n",
    "import markdown\n",
    "\n",
    "answer = response.candidates[0].content.parts[0].text\n",
    "html_answer = markdown.markdown(answer)\n",
    "\n",
    "print(html_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
